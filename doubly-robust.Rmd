---
title: Doubly Robust Estimation of Causal Effects
author: Francesca Vescia
date: Spring 2024
output: pdf_document
---

Welcome! This is a conversational introduction to doubly robust estimation. Largely following [[Funk et al. 2011]{.underline}](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3070495/), we’ll talk about what doubly robust estimation is and why we do it; break down a simple doubly robust estimator to understand how it works; and run some simulations to see our estimator in action.

## What and why

I like to think of “causal inference” as a catch-all term for the tools we have to figure out whether relationships we see in the world are cause and effect or just coincidence. Often, we learn about these relationships by modeling them: we collect data on something we’re curious about and fit models to that data to help us see the patterns in it. Models capture patterns in the data in the form of numerical estimates.

But fitting models to data almost always involves making some assumptions about how the world works. For example, when we fit a linear regression model, we assume the relationship we are quantifying is linear. And when we misspecify our models – that is, when our assumptions about the world are wrong – the estimates our models produce are poor.

Doubly robust estimation is one way to help insure our estimates against bad assumptions. It combines two modeling strategies, outcome regression modeling and propensity score estimation, in such a way that as long as one of the two models is correct, our estimates will be unbiased – even if the other model is misspecified.

You can think of doubly robust estimation as statistics’ version of the [[Swiss cheese model]{.underline}](https://www.nytimes.com/2020/12/05/health/coronavirus-swiss-cheese-infection-mackay.html). Each modeling strategy – propensity score estimation and outcome regression modeling – is a layer of defense against bias. Neither is perfect, but by layering the strategies on top of each other, we give ourselves more opportunities to block bias from degrading our estimates.

## Some housekeeping

First things first, notation. I follow Funk et al., except that I use $D$ instead of $X$ to denote treatment, to avoid confusion given you’ll often see $X$ used elsewhere to denote covariates. Here is a full list of the terms we’re going to use:

$\bf{Z}$ are characteristics (that is, covariates) of individuals in our data

$D$ is a binary treatment indicator equal to $1$ if an individual is exposed to treatment or $0$ if they aren’t

$Y_{D=1}$ and $Y_{D=0}$ are *observed* outcomes for individuals in the treatment and control groups, respectively

$\hat{Y_1}$ and $\hat{Y_0}$ are *predicted* outcomes under treatment and control, respectively [^1]

[^1]: Per usual, any term with a "hat" is an estimate of a true quantity we can't measure directly

$m1(\bf{Z_i}$$, \hat{\alpha}_1)$ and $m0(\bf{Z_i}$$, \hat{\alpha}_0)$ are the models we’ll use to predict $\hat{Y}_{D=1}$ and $\hat{Y}_{D=0}$ for each individual, where $\bf{Z_i}$ are that individual's characteristics and $\hat{\alpha}_1$ and $\hat{\alpha}_0$ are coefficients that describe the estimated relationships between characteristics and outcomes in the treatment and control groups; we get $\hat{\alpha}_1$ and $\hat{\alpha}_0$ by fitting linear regression models that predict outcomes using characteristics

$PS=P[D=1|\bf{Z}]$ is the propensity score, which measures how likely an individual is to be exposed to treatment based on their characteristics

$e(\bf{Z_i}$$, \hat{\beta})$ is the model we'll use to estimate the propensity score, where $\bf{Z_i}$ are once again an individual's characteristics and $\hat{\beta}$ is a coefficient that describes the estimated relationship between characteristics and treatment propensity; we get $\hat{\beta}$ by fitting a logistic regression model that predicts treatment using characteristics

$DR_1$ and $DR_0$ are the doubly robust estimated outcomes under treatment and control

Also, a few assumptions. Briefly, **positivity** or overlap assumes every individual in the data had some chance of receiving treatment: formally, $0\leq P[D_i=1]\leq1$. It ensures we have individuals in the treatment and control groups to contrast. **Consistency** or the stable unit treatment assumption (SUTVA) assumes every individual has a single, stable potential outcome for each possible treatment: formally, Yi(d) = Yi if Di = d. SUTVA has several implications; see Anton Strezhnev’s [[introduction to the potential outcomes framework]{.underline}](https://github.com/UChicago-pol-methods/plsc-30600-causal-inference/blob/main/slides/week1/Week%201_%20Potential%20Outcomes.pdf) for an excellent summary. Finally, **exchangeability**, the assumption that the outcome distributions would be the same if the treatment assignments had been flipped, implies treatment assignment is independent of potential outcomes. As we will see, this assumption is key to making the doubly robust estimator work.

## A simple doubly robust estimator

Let's break down the doubly robust estimator mathematically and programmatically. We'll use the notation defined above for our proofs, and we'll fit our models on simulated data. If you're curious, see Funk et al. [Web Appendix 3](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3070495/bin/supp_173_7_761__index.html) for the exact details of the data-generating process and [[GitHub]{.underline}](https://github.com/fvescia/doubly-robust) for the code. The main things to know are that treatment ($D$) and outcomes ($Y$) are both a function of individual characteristics ($\bf{Z}$ [^2]), but outcomes are *not* a function of treatment, so the true treatment effect is zero.

[^2]: The $Z_2$ / `z2` characteristic is only used for data generation, so you won't see it anywhere in this document.

```{r, echo=FALSE, message=FALSE}
library(tidyverse)
```

```{r, echo=FALSE, message=FALSE}
# GENERATE "TRUE" DATE PER FUNK ET AL. 2011
n = 2000

# GENERATE IVs
z1 <- rnorm(n, mean = 0, sd = 1)
z2 <- rnorm(n, mean = 0, sd = 1)
z3 <- replicate(n, ifelse((runif(1, min = 0, max = 1) <= 0.3), 1, 0))

# GENERATE EXPOSURE AS A FUNCTION OF IVs

# Set betas for true model
b0_0 = 1.5
b1_0 = 1
b2_0 = -2
b3_0 = 1

# Calculate true propensity scores (logit)
ps <- (1 + exp(-1 * (b0_0 + b1_0*z1 + b2_0*z2 + b3_0*z3)))^(-1)

# Calculate exposure
d <- ifelse((ps + runif(n, min = 0, max = 1)) < 0.91, 1, 0)

# GENERATE TRUE OUTCOMES
b4_0 <- 2
z4 <- rnorm(n, mean = 0, sd = 1)
y <- b1_0*z1 + b3_0*z3 + b4_0*z4

# TRUE DATA
data <- tibble(z1, z2, z3, d, ps, y)

(mean(data$d)) # Expect P(D=1) = 0.2
(mean(data$y)) # Expect mean = 0.2
(sd(data$y)) # Expect sd = 2.3
```

Recall that doubly robust estimation combines two modeling strategies, outcome regression modeling and propensity score estimation. We're going to correctly specify our outcome model and intentionally *misspecify* our propensity score model - that way we can see double robustness at work. (For anyone following along in Funk et al., this is their Scenario 3.)

Let's start with our outcomes: we model the relationships between characteristics ($\bf{Z}$) and outcomes ($Y$) in each exposure group, then use those models to predict outcomes ($\hat{Y}$) for everyone. This means each individual has one *observed* outcome, for the condition they are assigned to, and two *predicted* outcomes, one each for treatment and control.

```{r}
# Fit outcome regression models within exposure groups
mod_t <- lm(y ~ z1 + z3, data = data %>% filter(d == 1))
mod_c <- lm(y ~ z1 + z3, data = data %>% filter(d == 0))

# Predict outcomes for everyone
data <- data %>% mutate(yhat1 = predict(mod_t, data))
data <- data %>% mutate(yhat0 = predict(mod_c, data))
```

Now let's fit our propensity score model, purposefully leaving out $Z_3$, and the resulting, *misspecified* model to predict propensity scores:

```{r}
# Fit propensity score logit model
ps_mod <- glm(d ~ z1 + z3, data = data, family = 'binomial')

# Predict propensity scores
data <- data %>% mutate(ps_hat = predict(ps_mod, data))
```

And now, the fun part! We take our estimated outcomes and propensity scores and combine them to calculate doubly robust outcome estimates as shown in the table below. Just like when we calculated our regression-based $\hat{Y}s$, each person gets two estimates, one each for treatment and control.

```{=tex}
\begin{table}[h]
\begin{tabular}{llll}
& $DR_1$ & $DR_0$ &  \\
For $D=1$ & $\frac{Y_{D=1}}{PS}-\frac{\hat{Y_1}\left(1-PS\right)}{PS}$ & $\hat{Y_0}$ & \\
For $D=0$ & $\hat{Y_1}$ & $\frac{Y_{D=0}}{1-PS}-\frac{\hat{Y_0}\left(PS\right)}{1-PS}$ & 
\end{tabular}
\end{table}
```
```{r}
# Compute doubly robust estimates
data <- data %>% mutate(dr1 = 
                          ifelse(d == 1, 
                                 ((y / ps_hat) - ((yhat1 * (1 - ps_hat)) / (ps_hat))),
                                 (yhat1)),
                        dr0 =
                          ifelse(d == 1,
                                 (yhat0),
                                 ((y / (1 - ps_hat) - ((yhat0 * ps_hat) / (1 - ps_hat))))))
```

Finally, we take the averages of $DR_1$ and $DR_0$ across our entire sample and take the difference of those two averages as our estimated average treatment effect:

```{r}
# Compute ATE
(mean(data$dr1) - mean(data$dr0))
```

Let's think through what exactly is going on in the doubly robust estimator. You'll notice that that our doubly robust estimates of $DR_1$ for individuals in the control group and $DR_0$ for individuals in the treatment group are just $\hat{Y_1}$ and $\hat{Y_0}$, the predictions from our regression models. But our "within-condition" doubly robust estimates - that is, our $DR_1s$ for individuals in the treatment group and our $DR_0s$ for individuals in the control group - are a little fancier. We observe individuals' true outcomes under their assigned conditions, and we use that information together with our propensity score estimates to adjust our predictions.

Some rearranging can help us see how these adjustments block bias[^3]. The ordering and notation are a little different, but this equation ultimately does exactly the same math as the equations in the table above:

[^3]: The following proof is excerpted with minimal adaptation from Funk et al. [[Web Appendix 1]{.underline}](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3070495/bin/supp_173_7_761__index.html), which is in turn adapted from [[Tsiatis 2006]{.underline}](https://link.springer.com/book/10.1007/0-387-37345-4).

$$
\hat{\Delta}_{DR} = \frac{1}{n}\sum_{i=1}^n[\frac{D_iY_i}{e(Z_i,\hat{\beta})} - \frac{(D_i-e(Z,\hat{\beta}))}{e(Z,\hat{\beta})} m_1(Z_i,\hat{\alpha}_1)] - \frac{1}{n}\sum_{i=1}^n[\frac{(1-D_i)Y_i}{1-e(Z_i,\hat{\beta})}-\frac{(D_i-e(Z_i,\hat{\beta}))}{1-e(Z,\hat{\beta})}m_0(Z_i,\hat{\alpha}_0)]
$$
